---
title: "Tianjin"
author: "Caroline Colijn, Manu Saraswat, Michelle Coombe"
date: "`r Sys.Date()`"
output: 
  html_document:
    keep_md: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survminer)
library(survival)
library(tidyverse)
library(lubridate)
library(icenReg)
library(igraph)
library(visNetwork)
library(mvtnorm)
options(digits=3)
set.seed(1235) 
```

## Data 

Thanks to Dongxuan Chen and Louxin Zhang. These data are from three main sources:

* source1: http://wsjk.tj.gov.cn/col/col87/index.html#!uid=259&pageNum=1 (Tianjin health commission official website, for daily announcements)

* source2: https://weibo.com/u/2967529507 (Jinyun News, Tianjin offical local media weibo account, for patient symptom onset reference)

* source3: https://m.weibo.cn/status/IrrHI1FHm?jumpfrom=weibocom (another Tianjin local media weibo link, for mall cluster reference)


```{r}
tdata=read.csv("data/Tianjin135casesFeb22.csv",na.strings = "", stringsAsFactors = F)
tdata$symptom_onset=as.Date(tdata$symptom_onset, format = "%d/%m/%Y")
tdata$start_source=as.Date(tdata$start_source, format = "%d/%m/%Y")
tdata$end_source=as.Date(tdata$end_source,format = "%d/%m/%Y" )
tdata$confirm_date=as.Date(tdata$confirm_date,format = "%d/%m/%Y" )
glimpse(tdata)
```



## Incubation period

The incubation period is the time between exposure and the onset of symptoms. We estimate this directly from the stated start and end times for cases' exposure windows. Because it is explicitly about the symptom onset, we remove those who don't have symptom onset defined. These are a small minority of cases and the alternative would be to impute their symptom onset time using the others' delay to confirmation time.  For now, we remove them.  Then,  if no other end time for the exposure is given or  if the end of the exposure time is after the time of symptom onset, set the last exposure time to the symptom onset time. This is because they must have been exposed before symptom onset.  If no other start time is given, they must have been exposed since the start of the outbreak (Dec 1, 2019). These give us  the maximum and minimun incubation times. 

```{r}
#goodii=which(!is.na(tdata$symptom_onset))
which(is.na(tdata$symptom_onset)) #10 cases without date of symptom onset, and primarily later cases 

tdata$end_source[which(is.na(tdata$end_source))]=tdata$symptom_onset[which(is.na(tdata$end_source))]  # if no end exposure: set to symptom onset 
tdata$end_source = pmin(tdata$end_source, tdata$symptom_onset) # if end exposure after onset, set to onset 
tdata$start_source[which(is.na(tdata$start_source))]=as.Date("2019-12-01") # start date 

tdata$maxIncTimes=tdata$symptom_onset-tdata$start_source 
tdata$minIncTimes = tdata$symptom_onset-tdata$end_source

tdata$maxIncTimes
tdata$minIncTimes
tdata$maxIncTimes[27] = 50 # for some reason this was coming up negative 
```

We use survival analysis in the icenReg package to make parametric estimates, and we use the regular survival package to estimate the time to onset of symptoms. 

```{r}
ggsurvplot(
  fit=survfit(Surv(tdata$minIncTimes, tdata$maxIncTimes, type="interval2")~1, data=tdata), 
  xlab="Days",
  ylab = "Overall probability of no symptoms yet")
```

The median is about 8 days. For a parametric estimate we remove any remaining NAs and use interval censoring, because we know only that exposure was some time between the minimum and maximum possible values. 

```{r}
reddata=tdata[which(!is.na(tdata$minIncTimes)),]

getthreefits = function(reddata) {
  myfit = ic_par(Surv(reddata$minIncTimes, reddata$maxIncTimes,type="interval2")~1, data = reddata,dist="weibull")

myfit_gamma<- ic_par(Surv(reddata$minIncTimes, reddata$maxIncTimes, type="interval2") ~ 1, data = reddata, dist = "gamma")


myfit_lnorm =  ic_par(Surv(reddata$minIncTimes, reddata$maxIncTimes, type="interval2") ~ 1, data = reddata, dist = "lnorm")
return(list(myfit=myfit, myfit_gamma=myfit_gamma, myfit_lnorm=myfit_lnorm))
}

allthree=getthreefits(reddata)
myfit=allthree$myfit
myfit_gamma=allthree$myfit_gamma
myfit_lnorm=allthree$myfit_lnorm
```

We want to report (1) the parameters for these fits and the quantiles (including median). This describes the distribution.

Then we want to report (2) the resulting mean (95% CI for the mean). This describes our uncertainty in the distribution. 

(1) For the point estimates, get the parameters and quantiles for these  distributions. For Weibull and gamma distributions, the two parameters are shape and scale. For log normal they are mu and sdlog. 

```{r}
getQuantileDF <- function(myfit,myfit_gamma,myfit_lnorm) {
interqs=getFitEsts(myfit, newdata = NULL, p=c(0.025, 0.25, 0.5, 0.75,0.975)) #
interqs_gamma <- getFitEsts(myfit_gamma, newdata=NULL,  p
                      =c(0.025, 0.25, 0.5, 0.75, 0.975))

interqs_lnorm <- getFitEsts(myfit_lnorm, newdata=NULL,  p
                      =c(0.025,  0.25, 0.5, 0.75, 0.975))
mm=rbind(interqs, interqs_gamma, interqs_lnorm)
colnames(mm)=paste("q_",c(0.025, 0.25, 0.5, 0.75, 0.975),sep="")

df=as.data.frame(mm); df$distr =c("Weibull","Gamma","Log normal")
df$par1=c(exp(myfit$coefficients[1]), exp(myfit_gamma$coefficients[1]), 
          myfit_lnorm$coefficients[1])
df$par2=c(exp(myfit$coefficients[2]), exp(myfit_gamma$coefficients[2]), 
          exp(myfit_lnorm$coefficients[2]))
rownames(df)=NULL

return(df[,c(6,7,8,1:5)])
}

getQuantileDF(myfit,myfit_gamma,myfit_lnorm)
```


(2) Now we want the mean and 95% CIs on the shape, the scale and the resulting  mean. The "myfit" objects contain the estimates and covariance for these. Without wanting to code up the theory, the quick approach is to resample the shape and scale with appropriate covariance and compute the resampled means, then take the 95\% CIs. The functional form is different for the three different distributions. 

```{r}
getMeanCI <- function(statfit, dist = "weibull") {
  if (dist == "weibull") {
  x=exp(rmvnorm(n=10000, mean = statfit$coefficients, sigma=statfit$var))
  mymeans=x[,2]*gamma(1+1/x[,1]) # shape, scale for weibull 
  par1=exp(statfit$coefficients[1])
   par2=exp(statfit$coefficients[2])
  par1range=c(exp(log(par1)-1.96*sqrt(statfit$var[1,1])), exp(log(par1)+1.96*sqrt(myfit$var[1,1])))
   par2range=c(exp(log(par2)-1.96*sqrt(statfit$var[2,2])), exp(log(par2)+1.96*sqrt(myfit$var[2,2])))
  }
  if (dist == "gamma") {
      x=exp(rmvnorm(n=10000, mean = statfit$coefficients, sigma=statfit$var)) # shape, scale for gamma
      mymeans = x[,1]*x[,2] # gamma: mean  is shape*scale
  par1=exp(statfit$coefficients[1])
   par2=exp(statfit$coefficients[2])
  par1range=c(exp(log(par1)-1.96*sqrt(statfit$var[1,1])), exp(log(par1)+1.96*sqrt(myfit$var[1,1])))
   par2range=c(exp(log(par2)-1.96*sqrt(statfit$var[2,2])), exp(log(par2)+1.96*sqrt(myfit$var[2,2])))
  }
  if (dist == "lognorm") {
  x=rmvnorm(n=10000, mean = statfit$coefficients, sigma=statfit$var) 
  # these are the log of the mean, and the log of sd? 
  # mean is exp(mu + 0.5 sig^2) 
  mymeans=exp(x[,1]+0.5*exp(x[,2])^2) # i think
  par1=statfit$coefficients[1]
   par2=exp(statfit$coefficients[2])
    par1range=c(par1-1.96*sqrt(statfit$var[1,1]), par1+1.96*sqrt(myfit$var[1,1]))
   par2range=c(exp(statfit$coefficients[2]-1.96*sqrt(statfit$var[2,2])), exp(statfit$coefficients[2]+1.96*sqrt(statfit$var[2,2])))
  }
return(list(par1=par1,par2=par2, par1range=par1range, par2range=par2range, means=mymeans, qs = quantile(mymeans, probs = c(0.025, 0.5, 0.975)), meanmeans=mean(mymeans), sdmeans=sd(mymeans)))
}
```

Table for parameters and their CIs, and the  mean incubation period and its CI, for unstratified data: 

```{r}
getMeanCI_DF = function(myfit,myfit_gamma,myfit_lnorm) {
out_weib=getMeanCI(statfit = myfit, dist = "weibull")
out_gamm = getMeanCI(statfit =myfit_gamma, dist = "gamma")
out_lnorm=getMeanCI(statfit =myfit_lnorm, dist="lognorm")
return(data.frame(par1s=c(out_weib$par1, 
                          out_gamm$par1, 
                          out_lnorm$par1),
                   par1lower=c(out_weib$par1range[1], 
                          out_gamm$par1range[1], 
                          out_lnorm$par1range[1]),
                  par1upper=c(out_weib$par1range[2], 
                          out_gamm$par1range[2], 
                          out_lnorm$par1range[2]), # there is a better way .. but.
                  par2s=c(out_weib$par2, 
                          out_gamm$par2, 
                          out_lnorm$par2),
               par2lower=c(out_weib$par2range[1], 
                          out_gamm$par2range[1], 
                          out_lnorm$par2range[1]),
                  par2upper=c(out_weib$par2range[2], 
                          out_gamm$par2range[2], 
                          out_lnorm$par2range[2]), # there is a better way .. but.
                  means=c(out_weib$meanmeans, 
                          out_gamm$meanmeans, 
                          out_lnorm$meanmeans),
           meanlower=c(out_weib$qs[1], out_gamm$qs[1],
                     out_lnorm$qs[1]),
           meanupper=c(out_weib$qs[3],out_gamm$qs[3],
                     out_lnorm$qs[3])))
}
getMeanCI_DF(myfit,myfit_gamma,myfit_lnorm)
```



Plot a fit and the KM curve together. 

```{r}
# days=seq(0,20,by=0.05)
# density=dweibull(days, shape = exp(myfit$coefficients[1]), scale = exp(myfit$coefficients[2]))
# 
# ggs = ggsurvplot(
#   fit=survfit(Surv(tdata$minIncTimes, tdata$maxIncTimes, type="interval2")~1, data=tdata), 
#   xlab="Days",  ylab = "Overall probability of no symptoms yet")
# 
# pdata <- data.frame(days=rep(days,3),  
#             fitsurv=c(1-pweibull(days, shape = exp(myfit$coefficients[1]), scale = exp(myfit$coefficients[2])),
#         1-pgamma(days,  shape = exp(myfit_gamma$coefficients[1]), scale = exp(myfit_gamma$coefficients[2])),
#         1-plnorm(days,  meanlog = myfit_lnorm$coefficients[1], sdlog = exp(myfit_lnorm$coefficients[2]))),distn=c(rep("Weibull", length(days)), rep("Gamma",length(days)), rep("Lognorm", length(days)) ))  # i know, i know... 
# 
# 
# tmp=data.frame(days=days,  fitsurv=1-pweibull(days, shape = exp(myfit$coefficients[1]),
#                       scale = exp(myfit$coefficients[2])))
# ggs$plot + geom_line(data = tmp, aes(x = days, y = fitsurv))
# ggsave(filename = "inc_Tianjin.pdf", width = 8, height = 6)
```

### Make Figure 3b upper panel (non-stratified) for the manuscript
This is to plot the Kaplan-Meier survival curve and estimated probability distribution of days post-infection for a case not to be showing symptoms yet (using three possible distributions: weibull, gamma, and log-normal).
```{r}
days=seq(0,20,by=0.05)

ggs = ggsurvplot(
  fit=survfit(Surv(tdata$minIncTimes, tdata$maxIncTimes, type="interval2")~1, data=tdata),
  xlab="Days",  ylab = "Overall probability of no symptoms yet",palette = 'lancet',legend=c('right'))

pdata <- data.frame(days=rep(days,3),  
            fitsurv=c(1-pweibull(days, shape = exp(allthree$myfit$coefficients[1]), scale = exp(allthree$myfit$coefficients[2])),
        1-pgamma(days,  shape = exp(allthree$myfit_gamma$coefficients[1]), scale = exp(allthree$myfit_gamma$coefficients[2])),
        1-plnorm(days,  meanlog = allthree$myfit_lnorm$coefficients[1], sdlog = exp(allthree$myfit_lnorm$coefficients[2]))),distn=c(rep("Weibull", length(days)), rep("Gamma",length(days)), rep("Lognorm", length(days)) ))  # i know, i know... 

ggs$plot +geom_line(data = pdata, aes(x = days, y = fitsurv,color=distn))
# ggsave(filename = "final_figures/Fig3b_inc_Tianjin_all.pdf", width = 8, height = 6)
```


### Stratified early and late 
Finally, we want to do this all again but stratifying the data between early occurring cases and late. This is why we used functions in the above, though it was clumsy. *Early and late date of symptom onset seems to make sense in Tianjin dataset, but let's see if source of infection (Wuhan/travel vs. not) is more reasonable, just like in Singapore. HOWEVER, unlike Singapore, the epidemiology of Wuhan vs. Tianjin is unlikely to be that different, so maybe it makes more sense to continue to split based on the date of symptom onset.

```{r}
### Stratifying based on "early" = has symptom_onset on or before Jan 31, 2020 vs. "late" = has symptom_onset after Jan 31, 2020
# earlydata=tdata[which(!is.na(tdata$minIncTimes) & tdata$symptom_onset <= as.Date("2020-01-31")),]
# latedata=tdata[which(!is.na(tdata$minIncTimes) & tdata$symptom_onset > as.Date("2020-01-31")),]

### Stratifying based on "early" = infection_source is Wuhan or travel vs. "late" = infection_source is not Wuhan or travel

# Make a column for sensible groupings for Tianjin, based on the reason why the case was exposed
# Turn 'Infection_source' into lower case and get trim any whitespace so don't have issues with case sensitivity, etc
tdata$Infection_source <- str_to_lower(tdata$Infection_source)
tdata$Infection_source <- str_trim(tdata$Infection_source)
table(tdata$Infection_source)
sum(is.na(tdata$Infection_source)) #3 NAs

#Note that the order the data are selected in is VERY important to which case goes into which source_group category
  #For those that meet multiple criteria (e.g. wuhan; tj1), the str_match which is highest in the case_when call (i.e. "wuhan|hubei") will have priority over those matching later 
  #so that the 'source' column contain "wuhan; tj1" would be labelled as infection from a "wuhan" rather than from a "known relationship" origin 

#Decision rule applied to cluster naming classification:
  #Highest priority: 1) Known outbreak cluster locations (e.g. Wuhan/Hubei, mall, or church)
  #                  2) Known close relationship to another case (i. family; ii. work; iii. other known direct contact)
  #                  3) Known travel history to non-outbreak locations or unclear destinations
  #                  4) Any other listed associations (e.g. being part of a particular at-risk group such as airport worker)
  #Lowest priority:  5) No known source of possible viral exposure

#See what happens when we emphasize the wuhan and travel cases over known relationships
  #This seems more logical, given that the epicenter of the outbreak was Wuhan
tdata <- mutate(tdata, source_group = case_when(!is.na(str_match(Infection_source, "wuhan|hubei")) ~ "Wuhan and Hubei", #Priority 1
                                                  !is.na(str_match(Infection_source, "mall|store|shopper")) ~ "Mall", #Priority 1
                                                  !is.na(str_match(Infection_source, "family|relative|wife|mother|son|sister|husband")) ~ "Relative", #Priority 2
                                                  !is.na(str_match(Infection_source, "coworker|business|workplace|colleague")) ~ "Coworker", #Priority 2
                                                  !is.na(str_match(Infection_source, "tj|patient")) ~ "Known relationship", #Priority 2
                                                  !is.na(str_match(Infection_source, "train|travel|trip|hebei|dalian")) ~ "Other travel", #Priority 3
                                                  !is.na(str_match(Infection_source, "unknown|unclear")) ~ "Unknown", #Priority 5
                                                  is.na(Infection_source) ~ "Unknown", #Priority 5
                                                  T ~ "other")) #there should be none of these, so this is just a sanity check!  
table(tdata$source_group) 
  #4 cases switch from being source "known relationship" to either "wuhan" (3 cases) or "location unclear travel" (1 case)


#Filter tiajin data into early vs. late (based on wuhan origin vs. not wuhan as probable infection sources)
earlydata <- filter(tdata, source_group %in% c("Wuhan and Hubei")) #26 observations
latedata  <- filter(tdata, source_group != "Wuhan and Hubei") #109 observations

range(earlydata$symptom_onset, na.rm = T) # "2020-01-14" to  "2020-02-02"
range(latedata$symptom_onset, na.rm = T)  # "2020-01-15" to  "2020-02-19"
  #Hmm...not really much difference between "early" and "late" timing...
```

Make a dotplot to explore disease progression across different groups; to understand disease progression might be changing between different infection sources, and how that relates to our "early" vs. "late" datasets. 
```{r}
### Can make a dotplot to explore the distribution of disease progression dates in our dataset
t.dotplot <- tdata %>% 
                  select(c("case_id", "source_group", "symptom_onset", "end_source", "start_source")) %>% 
                  pivot_longer(cols = c("symptom_onset", "end_source", "start_source"),
                               names_to = "disease.progression",
                               values_to = "dates") %>% 
                  mutate(case_id = as.factor(case_id),
                         disease.progression = factor(disease.progression,
                                                      levels = c("symptom_onset", "end_source", "start_source")))

dotplot.key <- data.frame(dz.prog = c("symptom_onset", "end_source", "start_source"),
                          dz.shapes = c(1, 2, 3))

ggplot(t.dotplot, aes(x = dates, y = case_id)) +
  geom_point(aes(shape = disease.progression, color = source_group), size = 2) +
  geom_vline(xintercept = ymd("2020-01-31"), color = "steelblue") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        #axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.y = element_line(color = "grey90", linetype = "dashed")) +
  scale_x_date(date_breaks = "1 day") +
  scale_shape_manual(values = dotplot.key$dz.shapes)
```


Fit to the three distributions: 

```{r}
Eallthree=getthreefits(earlydata)
Lallthree=getthreefits(latedata)  
  #TODO: fix this with latedata as "non-Wuhan"...
  #The error is "Error in yMat[exact, 2] <- yMat[exact, 1] : NAs are not allowed in subscripted assignments"
```

EARLY: parameter point estimates and the quantiles

```{r}
getQuantileDF(Eallthree[[1]],Eallthree[[2]], Eallthree[[3]])
```

LATE: parameter point estimates and the quantiles

```{r}
getQuantileDF(Lallthree[[1]],Lallthree[[2]], Lallthree[[3]])
```

EARLY: how variable are these point estimates? Look at mean and 95\% CI

```{r}
getMeanCI_DF(Eallthree[[1]],Eallthree[[2]], Eallthree[[3]])
```

LATE: how variable are these point estimates? Look at mean and 95\% CI

```{r}
getMeanCI_DF(Lallthree[[1]],Lallthree[[2]], Lallthree[[3]])
```

### Generating Figure 3b (lower panel) for manuscript
This is to plot the Kaplan-Meier survival curves and estimated probability distribution of days post-infection for a case not to be showing symptoms yet, when stratifying the data pre and post quarantine procedures in China. As per tables above, the symptom onset date of on or before Jan 31, 2020 is the cut-off for what defines an "early" case. 
```{r}
#Generating Figure 3 for the paper
tdays=seq(0,20,by=0.05)

fit1<-survfit(Surv(earlydata$minIncTimes, earlydata$maxIncTimes, type="interval2")~1, data=earlydata)
fit2<-survfit(Surv(latedata$minIncTimes, latedata$maxIncTimes, type="interval2")~1, data=latedata)

fit <- list(early = fit1, late = fit2)
ggsp2=ggsurvplot(fit, data = tdata, combine = TRUE, # Combine curves
             # Clean risk table
           palette = "lancet",legend.labs=c("Pre-quarantine","Post-quarantine"),legend=c('right'))

pdata <- data.frame(days=rep(tdays,3),  
            fitsurv=c(1-pweibull(tdays, shape = exp(Eallthree$myfit$coefficients[1]), scale = exp(Eallthree$myfit$coefficients[2])),
        1-pgamma(tdays, shape = exp(Eallthree$myfit_gamma$coefficients[1]), scale = exp(Eallthree$myfit_gamma$coefficients[2])),
        1-plnorm(tdays,  meanlog = Eallthree$myfit_lnorm$coefficients[1], sdlog = exp(Eallthree$myfit_lnorm$coefficients[2]))),distn=c(rep("Weibull", length(tdays)), rep("Gamma",length(tdays)), rep("Lognorm", length(tdays)) )) 
                                                            
pdata1 <- data.frame(days=rep(tdays,3),  
            fitsurv=c(1-pweibull(tdays, shape = exp(Lallthree$myfit$coefficients[1]), scale = exp(Lallthree$myfit$coefficients[2])),
        1-pgamma(tdays,  shape = exp(Lallthree$myfit_gamma$coefficients[1]), scale = exp(Lallthree$myfit_gamma$coefficients[2])),
        1-plnorm(tdays,  meanlog = Lallthree$myfit_lnorm$coefficients[1], sdlog = exp(Lallthree$myfit_lnorm$coefficients[2]))), distn=c(rep("Weibull", length(tdays)), rep("Gamma",length(tdays)), rep("Lognorm", length(tdays)) )) 
                                                            
ggsp2$plot + geom_line(data = pdata, aes(x = days, y = fitsurv, color=distn)) +geom_line(data = pdata1, aes(x = days, y = fitsurv, color=distn)) 

ggsave(filename = "final_figures/Fig3b_inc_Tianjin_strata.pdf", width = 8, height = 6)
#ggsave(filename = "inc_Tianjin_strata.png", width = 8, height = 6)
```


## Serial interval 
We will estimate the serial interval using the 'interval case to case' approach given in Vink et al (https://academic.oup.com/aje/article/180/9/865/2739204). 

The dataset has quite a few instances where a putative infector or contact is known. These are listed in the 'Infection_source' column. We first make a graph in which nodes are individuals and edges are present from cases listed as possible sources, to the cases for whom they are possible sources. 

```{r}
mynodes = tdata$case_id
mynodes <- str_to_lower(mynodes) #to keep consistent with infection source column
tdata$case_id <- str_to_lower(tdata$case_id)

edges = data.frame(from=mynodes[9],to=mynodes[21],stringsAsFactors = F ) # i read this one manually 

for (id in 1:nrow(tdata)) {
tonode=tdata$case_id[id]
fromnodes=str_extract_all(tdata$Infection_source[id], "tj\\d+", simplify = T) #in lower case due to above early/late split on infection source
  if (length(fromnodes)>0) {
    for (k in 1:length(fromnodes)) {
      edges=rbind(edges, c(fromnodes[k], tonode))
    }
  }
}
head(edges)
edges=edges[-1,]
edges=edges[-which(is.na(edges[,1])),] # NAs arose from a few empty entries for Infection_source 
```

From this edge list we can use visNetwork to visualise the graph. Colours are from the infection source group column (but we should have a better colour scheme, like date of symptom onset). 

```{r}
edges$arrows="to"
nodes = data.frame(id=tdata$case_id, 
                   label=tdata$case_id,
                   group=tdata$source_group)
visNetwork(nodes,edges) %>% visLegend()
```

The interval case to case (ICC) data are the times between the (presumed) index case for a small cluster and the other cases in the cluster. The Vink et al approach allows these intervals to be one of 4 types, and estimates the serial interval and the probability of each type. To extract ICC intervals, we let the clusters be the components of the graph, and we let the presumed index case be the first to develop symptoms. For each cluster, we subtract the index cases' symptom time from the symtom times of the rest of the cluster (or just the first few; it turns out that the estimate is not sensitive to this). This results in a list of time intervals between symptom onset in presumed index cases and symptom onset in other cases in the same cluster (graph component). 


First construct the graph

```{r}
#serialdata=edges # REMOVE? 
#serialdata$symps_from = tdata$symptom_onset[match(edges$from, tdata$case_id)]
#serialdata$symps_to=tdata$symptom_onset[match(edges$to, tdata$case_id)]
tgraph = graph_from_edgelist(as.matrix(edges[,1:2]), directed = FALSE)
ccs=components(tgraph)

tdata$component=vapply(tdata$case_id, function(x)
  { if (x %in% names(ccs$membership)) { return(ccs$membership[match(x, names(ccs$membership))])
  } else { 
    return(NA)}}, FUN.VALUE = 3)
```


Extract ICC interval data: a function 

```{r}
 getICCs <- function(thisdata, ccs, K, orderby= "onset" ) {
  iccs=1
    for (n in 1:max(ccs$membership)) {
      mycases  = which(thisdata$component==n)
      if (orderby == "onset")
          {  myonsets = sort(thisdata$symptom_onset[mycases])[1:min(K, length(mycases))]}
        if (orderby == "exposure") {
          myonsets =thisdata$symptom_onset[mycases][order(thisdata$end_source[mycases])][1:min(K,length(mycases))]
          }
      iccs =c(iccs, myonsets[-1]-myonsets[1])
        }
    return(iccs[-1]) 
    }
```


Note that we are removing cases that do NOT have a date of symptom onset to determine the ICC. There are 10 cases without symptom onset, but all have a confirmation date.
```{r}
stdata = tdata[which(!is.na(tdata$symptom_onset)),]  #10 observations

icc3 = getICCs(stdata,ccs,3)
icc4 = getICCs(stdata,ccs,4)
icc5 = getICCs(stdata,ccs,5)
icc6 = getICCs(stdata,ccs,6)
icc_expose = getICCs(stdata, ccs, 4, orderby ="exposure")
```

Perform the estimate using the Vink et al method, and display the result:

```{r}
source("TianjinSI_VinkWallinga_CC.R")
    #Changed to N = 50 to be consistent with Singapore analysis
myest3 = serial_mix_est(data=icc3, N=50, startmu=10, startsig =4)
myest4 = serial_mix_est(data=icc4, N=50, startmu=10, startsig =4)
myest5 = serial_mix_est(data=icc5, N=50, startmu=10, startsig =4)
myest6 = serial_mix_est(data=icc6, N=50, startmu=10, startsig =4)
myest_exp= serial_mix_est(data=icc_expose, N=50, startmu=10, startsig =4)

mm=rbind(myest3, myest4, myest5,myest6, myest_exp)
colnames(mm)=c("mu","sig")
mm=as.data.frame(mm)
mm$NumCasesPerCluster=c( 3, 4, 5, 6, 4) 
mm$ordering = c("Onset","Onset","Onset","Onset","LastExposure")
print(mm[,c(4,3,1,2)]) 
```

The mean SI is `r myest4[1]`. The standard deviation of the serial intervals is `r myest4[2]`.

We need CIs for the mean. For this we use bootstrapping. 

Bootstrap analysis code - have left it set to eval=FALSE in the Rmd because it takes time. Bootstraps computed on March 1 are in the file tianjin_bootstraps.Rdata. 

```{r, eval=FALSE}
# bootstrap analysis
Nboot=100
bestimates=myest4 
for (kk in 1:Nboot) {
  bdata = sample(x=icc4, size = length(icc4), replace = T)
  bestimates = rbind(bestimates, serial_mix_est(data=bdata, N=50, startmu=10, startsig =4))
  print(paste("loop iteration #", kk, sep = ": "))
}

# save(bestimates, file = "data/tianjin_boots_100.Rdata")
```

```{r,eval=TRUE}
load("data/tianjin_boots_100.Rdata")
mean(bestimates[,1]) # mean of the mean serial intervals
median(bestimates[,1])
mean(bestimates[,2]) # sd of the sd serial intervals 
sd(bestimates[,1]) # sd of the MEAN serial intervals 
```

The 95% range for the mean serial interval is (`r myest4[1]-1.96*sd(bestimates[,1])`, `r myest4[1]+1.96*sd(bestimates[,1])`).


Note, you need to run and save the following figure (part of Figure S1) manually (vs using knitr) for some reason:
```{r, eval=FALSE}
hist(bestimates[,1],breaks = 10)
bootdf=data.frame(mu=bestimates[,1], sig=bestimates[,2])
ggplot(bootdf, aes(x=mu, y=sig))+geom_point()

ggplot(bootdf, aes(x=mu))+geom_histogram()
# ggsave(file = "final_figures/FigS1_bootst_SI_tianjin.pdf", width = 6, height = 4)
```


#### Serial interval estimation based on early and late datasets
This section is to determine what impact dividing the dataset based on "early" cases (for Tianjin data, "early" is defined as cases where the presumed source of infection is travel from Wuhan or Hubei) vs "late" cases (for Tianjin data, "late" is defined as cases where the presumed source of infection is not from Wuhan or Hubei).

We will repeat the same steps as with the full dataset, on both the early and the late datasets. First step is to determine relationships between infectees and putative infectors by defining 'nodes' (= individuals; indicated by the CaseID of that row) and 'edges' (= relationships; indicate by the related_cases column in that lists the cases who are known possible sources of infection for that node) in both the early and late datasets.

**Early**: nodes and edges
```{r}
mynodes_e = earlydata$case_id  
mynodes_e <- str_to_lower(mynodes_e) #to keep consistent with infection source column
earlydata$case_id <- str_to_lower(earlydata$case_id)

edges_e = data.frame(from=mynodes_e[1],to=mynodes_e[24],stringsAsFactors = F ) # Looked up manually 

for (id in 1:nrow(earlydata)) {
tonode=earlydata$case_id[id]
fromnodes=str_extract_all(earlydata$Infection_source[id], "tj\\d+", simplify = T) #in lower case due to above early/late split on infection source
  if (length(fromnodes)>0) {
    for (k in 1:length(fromnodes)) {
      edges_e=rbind(edges_e, c(fromnodes[k], tonode))
    }
  }
}
head(edges_e)
edges_e=edges_e[-1,]

edges_e <- filter(edges_e, !is.na(from)) #Safer than using which(), in case there are no NAs
head(edges_e)
```

Early: visNetwork graph with color 'group' based on presumed source of infection.
```{r}
edges_e$arrows="to"
nodes_e = data.frame(id=earlydata$case_id, 
                   label=earlydata$case_id,
                   group=earlydata$source_group)
visNetwork(nodes_e,edges_e) %>% visLegend()
```

Early: Estimate the serial interval using the ICC method from Vink et al. 
```{r}
# 1. First construct a graph from edgelist
earlygraph = graph_from_edgelist(as.matrix(edges_e[,1:2]), directed = FALSE)
ccs_e=components(earlygraph)

earlydata$component=vapply(earlydata$case_id, function(x)
  { if (x %in% names(ccs_e$membership)) { return(ccs_e$membership[match(x, names(ccs$membership))])
  } else { 
    return(NA)}}, FUN.VALUE = 3)

# 2. Use the previously defined getICC function to extract the ICC from this graph object
  #Note that the integers refer to the number of cases per cluster used to determine the ICC
stdata_e = earlydata[which(!is.na(earlydata$symptom_onset)),]

icc3_e = getICCs(stdata_e,ccs_e,3)
icc4_e = getICCs(stdata_e,ccs_e,4)
icc5_e = getICCs(stdata_e,ccs_e,5)
icc6_e = getICCs(stdata_e,ccs_e,6)
icc_expose_e = getICCs(stdata_e, ccs_e, 4, orderby ="exposure")

# 3. Use the serial_mix_est function from the file ("TianjinSI_VinkWallinga_CC.R") sourced earlier
  #Changed to N = 50 to be consistent with Singapore analysis
myest3_e = serial_mix_est(data=icc3_e, N=50, startmu=10, startsig =4) 
myest4_e = serial_mix_est(data=icc4_e, N=50, startmu=10, startsig =4)
myest5_e = serial_mix_est(data=icc5_e, N=50, startmu=10, startsig =4)
myest6_e = serial_mix_est(data=icc6_e, N=50, startmu=10, startsig =4)
myest_exp_e= serial_mix_est(data=icc_expose_e, N=50, startmu=10, startsig =4)

mm_e=rbind(myest3_e, myest4_e, myest5_e, myest6_e, myest_exp_e)
colnames(mm_e)=c("mu","sig")
mm_e=as.data.frame(mm_e)
mm_e$NumCasesPerCluster=c( 3, 4, 5, 6, 4) 
mm_e$ordering = c("Onset","Onset","Onset","Onset","LastExposure")
print(mm_e[,c(4,3,1,2)]) 
```

The mean SI is `r myest4_e[1]`. The standard deviation of the serial intervals is `r myest4_e[2]`.

Early: Bootstrapping to determine the 95% confidence intervals for the serial interval
```{r, eval=FALSE}
# bootstrap analysis
Nboot=100
#bestimates_e = myestimate 
bestimates_e = myest4_e

for (kk in 1:Nboot) {
bdata = sample(x = icc4_e, 
               size = length(iccall), #TODO: is this icc_4_e I think???
               replace = T)
bestimates_e = rbind(bestimates_e, serial_mix_est(data=bdata, N=50, startmu=10, startsig =4))
print(paste("loop iteration #", kk, sep = ": "))
}
```

```{r,eval=TRUE}
load("data/tianjin_bootstraps_early.Rdata")
mean(bestimates_e[,1]) # mean of the mean serial intervals
median(bestimates_e[,1])
mean(bestimates_e[,2]) # sd of the sd serial intervals 
sd(bestimates_e[,1]) # sd of the MEAN serial intervals 
```

The 95% range for the mean serial interval is (`r myest4_e[1]-1.96*sd(bestimates_e[,1])`, `r myest4_e[1]+1.96*sd(bestimates_e[,1])`).

Note, you need to run and save the following figure (part of Figure S1) manually (vs using knitr) for some reason:
```{r, eval=FALSE}
hist(bestimates_e[,1],breaks = 10)
bootdf_e=data.frame(mu=bestimates_e[,1], sig=bestimates_e[,2])
ggplot(bootdf_e, aes(x=mu, y=sig)) + geom_point()

ggplot(bootdf_e, aes(x=mu))+geom_histogram()
# ggsave(file = "final_figures/bootst_SI_tianjin_early.pdf", width = 6, height = 4)
```
**CHECK THAT EARLY DATA SERIAL ESTIMATES RUNS ON PROPERLY GROUPED DATA**
This does NOT as almost all cases are individuals and not found in clusters (so getICC function returns empty objects instead of a vector of ICCs).



**Late**: nodes and edges
```{r}
mynodes_l = latedata$case_id  
mynodes_l <- str_to_lower(mynodes_l) #to keep consistent with infection source column
latedata$case_id <- str_to_lower(latedata$case_id)

edges_l = data.frame(from=mynodes_l[2],to=mynodes_l[3],stringsAsFactors = F ) # Looked up manually 

for (id in 1:nrow(latedata)) {
tonode=latedata$case_id[id]
fromnodes=str_extract_all(latedata$Infection_source[id], "tj\\d+", simplify = T) #in lower case due to above early/late split on infection source
  if (length(fromnodes)>0) {
    for (k in 1:length(fromnodes)) {
      edges_l=rbind(edges_l, c(fromnodes[k], tonode))
    }
  }
}
head(edges_l)
edges_l=edges_l[-1,]

edges_l <- filter(edges_l, !is.na(from)) #Safer than using which(), in case there are no NAs
head(edges_l)
```

Early: visNetwork graph with color 'group' based on presumed source of infection.
```{r}
edges_l$arrows="to"
nodes_l = data.frame(id=latedata$case_id, 
                    label=latedata$case_id,
                    group=latedata$source_group)
visNetwork(nodes_l,edges_l) %>% visLegend()
```

Early: Estimate the serial interval using the ICC method from Vink et al. 
```{r}
# 1. First construct a graph from edgelist
lategraph = graph_from_edgelist(as.matrix(edges_l[,1:2]), directed = FALSE)
ccs_l=components(lategraph)

latedata$component=vapply(latedata$case_id, function(x)
  { if (x %in% names(ccs_l$membership)) { return(ccs_l$membership[match(x, names(ccs$membership))])
  } else { 
    return(NA)}}, FUN.VALUE = 3)

# 2. Use the previously defined getICC function to extract the ICC from this graph object
  #Note that the integers refer to the number of cases per cluster used to determine the ICC

#Remove any cases with 'NA' with date of symptom onset
stdata_l <- filter(latedata, !is.na(symptom_onset))

icc3_l = getICCs(stdata_l,ccs_l,3)
icc4_l = getICCs(stdata_l,ccs_l,4)
icc5_l = getICCs(stdata_l,ccs_l,5)
icc6_l = getICCs(stdata_l,ccs_l,6)
icc_expose_l = getICCs(stdata_l, ccs_l, 4, orderby ="exposure")

# 3. Use the serial_mix_est function from the file ("TianjinSI_VinkWallinga_CC.R") sourced earlier
    #Changed to N = 50 to be consistent with Singapore analysis
myest3_l = serial_mix_est(data=icc3_l, N=50, startmu=10, startsig =4)
myest4_l = serial_mix_est(data=icc4_l, N=50, startmu=10, startsig =4)
myest5_l = serial_mix_est(data=icc5_l, N=50, startmu=10, startsig =4)
myest6_l = serial_mix_est(data=icc6_l, N=50, startmu=10, startsig =4)
myest_exp_l= serial_mix_est(data=icc_expose_l, N=50, startmu=10, startsig =4)

mm_l=rbind(myest3_l, myest4_l, myest5_l, myest6_l, myest_exp_l)
colnames(mm_l)=c("mu","sig")
mm_l=as.data.frame(mm_l)
mm_l$NumCasesPerCluster=c( 3, 4, 5, 6, 4) 
mm_l$ordering = c("Onset","Onset","Onset","Onset","LastExposure")
print(mm_l[,c(4,3,1,2)]) 
```

The mean SI is `r myest4_l[1]`. The standard deviation of the serial intervals is `r myest4_l[2]`.

Early: Bootstrapping to determine the 95% confidence intervals for the serial interval
```{r, eval=FALSE}
# bootstrap analysis
Nboot=100
#bestimates_l = myestimate 
bestimates_l = myest4_l

for (kk in 1:Nboot) {
  bdata = sample(x = icc4_l, 
                 size = length(icc4_l), 
                 replace = T)
  bestimates_l = rbind(bestimates_l, serial_mix_est(data=bdata, N=50, startmu=10, startsig =4))
  print(paste("loop iteration #", kk, sep = ": "))
}
```

```{r,eval=TRUE}
load("data/tianjin_bootstraps_late.Rdata")
mean(bestimates_l[,1]) # mean of the mean serial intervals
median(bestimates_l[,1])
mean(bestimates_l[,2]) # sd of the sd serial intervals 
sd(bestimates_l[,1]) # sd of the MEAN serial intervals 
```

The 95% range for the mean serial interval is (`r myest4_l[1]-1.96*sd(bestimates_l[,1])`, `r myest4_l[1]+1.96*sd(bestimates_l[,1])`).

Note, you need to run and save the following figure (part of Figure S1) manually (vs using knitr) for some reason:
```{r, eval=FALSE}
hist(bestimates_l[,1],breaks = 10)
bootdf_l=data.frame(mu=bestimates_l[,1], sig=bestimates_l[,2])
ggplot(bootdf_l, aes(x=mu, y=sig)) + geom_point()

ggplot(bootdf_l, aes(x=mu))+geom_histogram()
# ggsave(file = "final_figures/bootst_SI_tianjin_late.pdf", width = 6, height = 4)
```




### R0 estimation

We estimate R0 from Wallinga and Lipsitch Proc. Roy. Soc. B 2007 using the equation $R=\exp{r \mu - 1/2 r^2 \sigma^2}$. To obtain CIs for R, we use our bootstrap estimates of $\mu$ and $\sigma^2$ and simply resample R using this equation. 

Jung et al Scenario 1

```{r,eval=TRUE}
load("tianjin_bootstraps.Rdata") # in case in Rmd with above evals set to FALSE 
myrate=0.15

Rs=0*(1:100) 
for (n in 1:100) {
  Rs[n]= exp(myrate*bestimates[n,1] - 0.5*(myrate)^2*bestimates[n,2]^2)
}
hist(Rs,breaks = 30)
mean(Rs)
sd(Rs)
hist(Rs)
quantile(Rs, probs = c(0.025, 0.975))
```

The mean R is `r mean(Rs)` and the range is (`r mean(Rs)-1.96*sd(Rs)`, `r mean(Rs)+1.96*sd(Rs)`), based on the 1.96 standard deviations from the mean.  This agrees closely with the above quantiles. 


### Additional (uninteresting, we think) points we explored: 


The direct infections from case 34 according to the figure at https://mp.weixin.qq.com/s/x4HBXGFw5vnWU7nXXdyWVg. These were not included in the paper because the links were compiled by volunteers and they differed from the offical reports. 

```{r,eval=FALSE}
tdata$direct34=FALSE
contacts_fig = c(43,37,53,83,89,131,124,48,71,51,57,58,
                 66,68,50,73,74,87,78,80,36,92,110,111)
contacts_id=paste("TJ",contacts_fig,sep="")
tdata$direct34[match(contacts_id, tdata$case_id)]=TRUE
# now i need to subtract 34's onset time from these infectees' onset times 
SI34s= as.numeric(tdata$symptom_onset[which(tdata$direct34)])-as.numeric(tdata$symptom_onset[which(tdata$case_id=="TJ34")])
mean(as.numeric((SI34s)))# don't actually need all the as.numerics 
sd(SI34s)

```
Scenario 2: leads to  high R values, not in keeping with most analyses to date. 

```{r,eval=FALSE}
myrate=0.29
Rs=0*(1:100) 
for (n in 1:100) {
  Rs[n]= exp(myrate*bestimates[n,1] - 0.5*(myrate)^2*bestimates[n,2]^2)
}
hist(Rs,breaks = 30)
mean(Rs)
quantile(Rs, probs = c(0.025, 0.975))
```




